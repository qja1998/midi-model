import streamlit as st
import argparse  # Streamlitì—ì„œëŠ” ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ, ì›ë³¸ êµ¬ì¡° ìœ ì§€
import glob
import json
import os
import time
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Union, Optional, List

import numpy as np
import torch
import torch.nn.functional as F

# import tqdm # Streamlitì—ì„œëŠ” st.progress ì‚¬ìš©
from huggingface_hub import hf_hub_download
from transformers import DynamicCache
from safetensors.torch import load_file as safe_load_file

# --- í•„ìš”í•œ ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆ ì„í¬íŠ¸ ---
# (ì‹¤ì œ íŒŒì¼ë“¤ì´ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤)
try:
    import MIDI
    from midi_model import MIDIModel, config_name_list, MIDIModelConfig
    from midi_synthesizer import MidiSynthesizer
    from midi_tokenizer import MIDITokenizerV1, MIDITokenizerV2

    _modules_loaded = True
except ImportError as e:
    st.error(f"í•„ìˆ˜ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}. í•´ë‹¹ ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    _modules_loaded = False
# ------------------------------------

# --- ìƒìˆ˜ ë° ì´ˆê¸° ì„¤ì • ---
MAX_SEED = np.iinfo(np.int32).max
# OUTPUT_BATCH_SIZE = opt.batch # Streamlitì—ì„œëŠ” opt ëŒ€ì‹  ê³ ì •ê°’ ë˜ëŠ” ì…ë ¥ ì‚¬ìš©
DEFAULT_BATCH_SIZE = 1  # Streamlitì—ì„œëŠ” ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ë‹¨ìˆœí™”í•˜ê¸° ìœ„í•´ 1ë¡œ ì‹œì‘í•˜ê±°ë‚˜, ì‚¬ìš©ì ì…ë ¥ ë°›ë„ë¡ ìˆ˜ì • ê°€ëŠ¥
number2drum_kits = {
    -1: "None",
    0: "Standard",
    8: "Room",
    16: "Power",
    24: "Electric",
    25: "TR-808",
    32: "Jazz",
    40: "Blush",
    48: "Orchestra",
}
patch2number = {v: k for k, v in MIDI.Number2patch.items()} if _modules_loaded else {}
drum_kits2number = {v: k for k, v in number2drum_kits.items()}
key_signatures = [
    "Câ™­",
    "Aâ™­m",
    "Gâ™­",
    "Eâ™­m",
    "Dâ™­",
    "Bâ™­m",
    "Aâ™­",
    "Fm",
    "Eâ™­",
    "Cm",
    "Bâ™­",
    "Gm",
    "F",
    "Dm",
    "C",
    "Am",
    "G",
    "Em",
    "D",
    "Bm",
    "A",
    "Fâ™¯m",
    "E",
    "Câ™¯m",
    "B",
    "Gâ™¯m",
    "Fâ™¯",
    "Dâ™¯m",
    "Câ™¯",
    "Aâ™¯m",
]
key_sig_map_to_index = {name: i + 1 for i, name in enumerate(key_signatures)}
key_sig_map_to_index["auto"] = 0

# --- ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì „ì—­ ë³€ìˆ˜ (Streamlitì—ì„œëŠ” session_state ì‚¬ìš© ê¶Œì¥) ---
# model: Optional[MIDIModel] = None
# tokenizer: Union[MIDITokenizerV1, MIDITokenizerV2, None] = None

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "model" not in st.session_state:
    st.session_state.model = None
if "tokenizer" not in st.session_state:
    st.session_state.tokenizer = None
if "model_loaded" not in st.session_state:
    st.session_state.model_loaded = False
if "output_midi_seq" not in st.session_state:
    st.session_state.output_midi_seq = None  # ìƒì„±ëœ MIDI ì‹œí€€ìŠ¤ ì €ì¥ (ë°°ì¹˜ ê³ ë ¤ í•„ìš”)
if "continuation_state" not in st.session_state:
    st.session_state.continuation_state = [0]  # [int] or [list]
if "last_seed" not in st.session_state:
    st.session_state.last_seed = 0
if "output_files" not in st.session_state:
    st.session_state.output_files = []  # ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ ì €ì¥
if "output_audio_data" not in st.session_state:
    st.session_state.output_audio_data = []  # ìƒì„±ëœ ì˜¤ë””ì˜¤ ë°ì´í„° ì €ì¥

# --- Helper Functions (Gradio ì½”ë“œì—ì„œ ê°€ì ¸ì˜´, ì¼ë¶€ ìˆ˜ì •) ---


@st.cache_resource  # ì‚¬ìš´ë“œí°íŠ¸ ë° ì‹ ë””ì‚¬ì´ì €ëŠ” í•œ ë²ˆë§Œ ë¡œë“œ
def get_synthesizer():
    try:
        soundfont_path = hf_hub_download(
            repo_id="skytnt/midi-model", filename="soundfont.sf2"
        )
        return MidiSynthesizer(soundfont_path)
    except Exception as e:
        st.error(f"ì‚¬ìš´ë“œí°íŠ¸ ë¡œë”© ë˜ëŠ” ì‹ ë””ì‚¬ì´ì € ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


@st.cache_resource  # ìŠ¤ë ˆë“œ í’€ë„ í•œ ë²ˆë§Œ ìƒì„±
def get_thread_pool(max_workers=DEFAULT_BATCH_SIZE):
    return ThreadPoolExecutor(max_workers=max_workers)


synthesizer = get_synthesizer()
thread_pool = get_thread_pool()


@st.cache_data  # íŒŒì¼ ëª©ë¡ì€ ìºì‹± ê°€ëŠ¥
def get_model_paths():
    ckpt_files = glob.glob("**/*.ckpt", recursive=True)
    bin_files = glob.glob("**/*.bin", recursive=True)
    safetensors_files = glob.glob("**/*.safetensors", recursive=True)
    print(ckpt_files, bin_files, safetensors_files)
    model_paths = sorted(ckpt_files + bin_files + safetensors_files)
    model_paths = [
        model_path for model_path in model_paths if "adapter_model" not in model_path
    ]
    return model_paths


@st.cache_data
def get_lora_paths():
    lora_paths = sorted(glob.glob("**/adapter_config.json", recursive=True))
    lora_paths = [str(Path(lora_path).parent) for lora_path in lora_paths]
    return [""] + lora_paths  # ë¡œë¼ ë¯¸ì‚¬ìš© ì˜µì…˜ ì¶”ê°€


def load_model(path, model_config, lora_path, device):
    if not _modules_loaded:
        return "í•„ìˆ˜ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨"
    try:
        if model_config == "auto":
            config_path = Path(path).parent / "config.json"
            if config_path.exists():
                config = MIDIModelConfig.from_json_file(config_path)
            else:
                return "config.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì •ì„ ì§ì ‘ ì§€ì •í•´ì£¼ì„¸ìš”."
        else:
            config = MIDIModelConfig.from_name(model_config)

        model_instance = MIDIModel(config=config)
        tokenizer_instance = model_instance.tokenizer

        st.write(f"'{path}' ë¡œë”© ì¤‘...")
        if path.endswith(".safetensors"):
            state_dict = safe_load_file(path, device="cpu")  # CPUë¡œ ë¨¼ì € ë¡œë“œ
        else:
            ckpt = torch.load(path, map_location="cpu")  # CPUë¡œ ë¨¼ì € ë¡œë“œ
            state_dict = ckpt.get("state_dict", ckpt)

        model_instance.load_state_dict(state_dict, strict=False)
        st.write("ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ.")

        if lora_path:
            st.write(f"LoRA '{lora_path}' ë³‘í•© ì¤‘...")
            model_instance = model_instance.load_merge_lora(
                lora_path
            )  # load_merge_loraê°€ í•´ë‹¹ ê²½ë¡œë¥¼ ì²˜ë¦¬í•œë‹¤ê³  ê°€ì •
            st.write("LoRA ë³‘í•© ì™„ë£Œ.")

        # ëª¨ë¸ì„ ì§€ì •ëœ ì¥ì¹˜ë¡œ ì´ë™í•˜ê³  í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
        model_dtype = (
            torch.bfloat16
            if device == "cuda" and torch.cuda.is_bf16_supported()
            else torch.float32
        )
        model_instance.to(device, dtype=model_dtype).eval()
        st.write(f"ëª¨ë¸ì„ {device} ({model_dtype})ë¡œ ì´ë™ ë° í‰ê°€ ëª¨ë“œ ì„¤ì • ì™„ë£Œ.")

        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        st.session_state.model = model_instance
        st.session_state.tokenizer = tokenizer_instance
        st.session_state.model_loaded = True
        return "ëª¨ë¸ ë¡œë”© ì„±ê³µ!"

    except Exception as e:
        st.session_state.model = None
        st.session_state.tokenizer = None
        st.session_state.model_loaded = False
        return f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}"


@torch.inference_mode()
def generate(
    prompt=None,
    batch_size=1,
    max_len=512,
    temp=1.0,
    top_p=0.98,
    top_k=20,
    disable_patch_change=False,
    disable_control_change=False,
    disable_channels=None,
    generator=None,
    progress_bar=None,
):  # progress_bar ì¶”ê°€

    model = st.session_state.model
    tokenizer = st.session_state.tokenizer
    device = next(model.parameters()).device  # ëª¨ë¸ì—ì„œ í˜„ì¬ device ê°€ì ¸ì˜¤ê¸°

    if tokenizer is None or model is None:
        st.error("ëª¨ë¸ ë˜ëŠ” í† í¬ë‚˜ì´ì €ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return iter([])  # ë¹ˆ iterator ë°˜í™˜

    if disable_channels is not None:
        # disable_channels = [tokenizer.parameter_ids["channel"][c] for c in disable_channels] # ì›ë³¸ ì½”ë“œ: cëŠ” ì±„ë„ ë²ˆí˜¸ (0-15)
        # tokenizer.parameter_ids["channel"] ì˜ êµ¬ì¡° í™•ì¸ í•„ìš”. list ë˜ëŠ” dict ì¼ ìˆ˜ ìˆìŒ.
        # ë§Œì•½ listì´ê³  ì¸ë±ìŠ¤ê°€ ì±„ë„ ë²ˆí˜¸ë¼ë©´:
        valid_channel_ids = tokenizer.parameter_ids.get("channel", [])
        if valid_channel_ids:
            disable_channel_ids = [
                valid_channel_ids[c]
                for c in disable_channels
                if c < len(valid_channel_ids)
            ]
        else:
            disable_channel_ids = []

    else:
        disable_channel_ids = []

    max_token_seq = tokenizer.max_token_seq
    if prompt is None:
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„± (BOS í† í°)
        input_tensor = torch.full(
            (batch_size, 1, max_token_seq),
            tokenizer.pad_id,
            dtype=torch.long,
            device=device,
        )
        input_tensor[:, 0, 0] = tokenizer.bos_id
    else:
        # ì œê³µëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if isinstance(prompt, list):  # í† í¬ë‚˜ì´ì¦ˆëœ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¼ ê²½ìš°
            prompt = np.asarray(prompt, dtype=np.int64)

        if (
            len(prompt.shape) == 2
        ):  # (seq_len, token_dim) í˜•íƒœ -> (batch, seq_len, token_dim)
            prompt = prompt[None, ...]
            if prompt.shape[0] != batch_size:
                prompt = np.repeat(prompt, repeats=batch_size, axis=0)
        elif len(prompt.shape) == 3:  # (batch, seq_len, token_dim)
            if prompt.shape[0] != batch_size:
                # ë°°ì¹˜ í¬ê¸° ì¡°ì • (ì˜ˆ: ì²«ë²ˆì§¸ ìƒ˜í”Œ ë°˜ë³µ)
                prompt = np.repeat(prompt[:1], repeats=batch_size, axis=0)
        else:
            st.error(f"ì˜ëª»ëœ í”„ë¡¬í”„íŠ¸ í˜•íƒœ: {prompt.shape}")
            return iter([])

        # ì‹œí€€ìŠ¤ ê¸¸ì´ ì œí•œ ë° íŒ¨ë”©
        prompt = prompt[:, :, :max_token_seq]
        if prompt.shape[-1] < max_token_seq:
            prompt = np.pad(
                prompt,
                ((0, 0), (0, 0), (0, max_token_seq - prompt.shape[-1])),
                mode="constant",
                constant_values=tokenizer.pad_id,
            )

        input_tensor = torch.from_numpy(prompt).to(dtype=torch.long, device=device)

    # ëª¨ë¸ ì…ë ¥ ê¸¸ì´ ì œí•œ (ì˜ˆ: 4096) - ëª¨ë¸ ì„¤ì •ì— ë”°ë¼ ì¡°ì ˆ í•„ìš”
    # input_tensor = input_tensor[:, -4096:] # ì´ ë¶€ë¶„ì€ ëª¨ë¸ êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
    input_tensor = input_tensor[
        :, -model.config.n_positions // max_token_seq :
    ]  # ì˜ˆì‹œ: ëª¨ë¸ì˜ ìµœëŒ€ position ê¸°ë°˜

    cur_len = input_tensor.shape[1]  # í˜„ì¬ ì´ë²¤íŠ¸(í† í° ì‹œí€€ìŠ¤) ìˆ˜
    total_gen_len = max_len  # ëª©í‘œ ì´ ì´ë²¤íŠ¸ ìˆ˜

    # --- ìƒì„± ë£¨í”„ ---
    cache1 = DynamicCache()
    past_len = 0
    generated_events_count = 0

    # Streamlit ì§„í–‰ë¥  í‘œì‹œê¸° ì—…ë°ì´íŠ¸
    if progress_bar:
        progress_bar.progress(0.0)

    while cur_len < total_gen_len:
        end = [False] * batch_size
        # ë‹¤ìŒ context window ê³„ì‚° (ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ ê³ ë ¤)
        current_input = input_tensor[:, past_len:]
        hidden = model.forward(current_input, cache=cache1)[
            :, -1
        ]  # ë§ˆì§€ë§‰ hidden state ì‚¬ìš©

        next_token_seq = None
        event_names = [""] * batch_size
        cache2 = DynamicCache()  # í† í° ë‚´ë¶€ ìƒì„±ìš© ìºì‹œ

        # ê° ì´ë²¤íŠ¸ ë‚´ í† í° ìƒì„± (ìµœëŒ€ max_token_seq ë§Œí¼)
        for i in range(max_token_seq):
            mask = torch.zeros(
                (batch_size, tokenizer.vocab_size), dtype=torch.bool, device=device
            )  # bool ë§ˆìŠ¤í¬ ì‚¬ìš© ê¶Œì¥

            # ë§ˆìŠ¤í‚¹ ë¡œì§ (ì–´ë–¤ í† í°ì„ ìƒì„±í•  ìˆ˜ ìˆëŠ”ì§€ ì œí•œ)
            for b in range(batch_size):
                if end[b]:  # ì´ë¯¸ EOSê°€ ë‚˜ì˜¨ ë°°ì¹˜ëŠ” PADë§Œ ê°€ëŠ¥í•˜ê²Œ
                    mask[b, tokenizer.pad_id] = True
                    continue

                if i == 0:  # ì²« í† í°: ì´ë²¤íŠ¸ íƒ€ì… ë˜ëŠ” EOS
                    mask_ids = list(tokenizer.event_ids.values()) + [tokenizer.eos_id]
                    if disable_patch_change:
                        if tokenizer.event_ids.get("patch_change") in mask_ids:
                            mask_ids.remove(tokenizer.event_ids["patch_change"])
                    if disable_control_change:
                        if tokenizer.event_ids.get("control_change") in mask_ids:
                            mask_ids.remove(tokenizer.event_ids["control_change"])
                    mask[b, mask_ids] = True
                else:  # ì´ë²¤íŠ¸ íŒŒë¼ë¯¸í„° í† í°
                    if not event_names[
                        b
                    ]:  # ì´ì „ ìŠ¤í…ì—ì„œ ì´ë²¤íŠ¸ê°€ ê²°ì •ë˜ì§€ ì•Šì€ ê²½ìš° (ì˜¤ë¥˜ ìƒí™©?)
                        mask[b, tokenizer.pad_id] = True
                        continue

                    param_names = tokenizer.events.get(event_names[b], [])
                    if i > len(param_names):  # í˜„ì¬ ì´ë²¤íŠ¸ì˜ íŒŒë¼ë¯¸í„° ê°œìˆ˜ ì´ˆê³¼ ì‹œ PAD
                        mask[b, tokenizer.pad_id] = True
                        continue

                    param_name = param_names[i - 1]
                    param_mask_ids = tokenizer.parameter_ids.get(param_name, [])

                    if param_name == "channel":
                        param_mask_ids = [
                            pid
                            for pid in param_mask_ids
                            if pid not in disable_channel_ids
                        ]

                    if param_mask_ids:
                        mask[b, param_mask_ids] = True
                    else:  # ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ê°’ì´ ì—†ìœ¼ë©´ PAD
                        mask[b, tokenizer.pad_id] = True

            # ë¡œì§“ ê³„ì‚° ë° ìƒ˜í”Œë§
            logits = model.forward_token(
                hidden, next_token_seq[:, -1:] if i > 0 else None, cache=cache2
            )[:, -1]
            # ë§ˆìŠ¤í¬ ì ìš© (í™•ë¥  0ìœ¼ë¡œ ë§Œë“¤ê¸°) - ë§ˆìŠ¤í¬ê°€ Trueì¸ ê³³ë§Œ ì‚´ë¦¼
            logits[~mask] = -float("inf")

            # ì˜¨ë„ ì ìš© ë° í™•ë¥  ê³„ì‚°
            scaled_logits = logits / temp
            probs = torch.softmax(scaled_logits, dim=-1)

            # Top-k / Top-p ìƒ˜í”Œë§
            samples = model.sample_top_p_k(
                probs, top_p, top_k, generator=generator
            )  # sample_top_p_k êµ¬í˜„ í•„ìš”

            # ìƒì„±ëœ í† í° ì²˜ë¦¬
            if i == 0:
                next_token_seq = samples
                for b in range(batch_size):
                    if end[b]:
                        continue
                    eid = samples[b].item()
                    if eid == tokenizer.eos_id:
                        end[b] = True
                        event_names[b] = "EOS"  # EOS í‘œì‹œ
                    elif eid in tokenizer.id_events:
                        event_names[b] = tokenizer.id_events[eid]
                    else:  # ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë²¤íŠ¸ IDê°€ ìƒ˜í”Œë§ëœ ê²½ìš° (ì˜¤ë¥˜ ì²˜ë¦¬)
                        end[b] = True
                        event_names[b] = "Error"
                        next_token_seq[b] = tokenizer.pad_id  # PADë¡œ ê°•ì œ ë³€ê²½
            else:
                next_token_seq = torch.cat([next_token_seq, samples], dim=1)
                # ëª¨ë“  í™œì„± ë°°ì¹˜ê°€ í˜„ì¬ ì´ë²¤íŠ¸ì˜ íŒŒë¼ë¯¸í„° ìƒì„±ì„ ì™„ë£Œí–ˆëŠ”ì§€ í™•ì¸
                all_params_done = True
                for b in range(batch_size):
                    if not end[b]:
                        event_name = event_names[b]
                        if event_name and event_name != "EOS" and event_name != "Error":
                            expected_len = len(tokenizer.events.get(event_name, []))
                            if i <= expected_len:  # ì•„ì§ íŒŒë¼ë¯¸í„° ìƒì„± ì¤‘
                                all_params_done = False
                                break
                        elif not event_name:  # ì´ë²¤íŠ¸ ê²°ì • ì•ˆë¨ (ì˜¤ë¥˜)
                            pass
                if all_params_done:
                    break  # í˜„ì¬ ì´ë²¤íŠ¸ ìƒì„± ì™„ë£Œ

        # ìƒì„±ëœ í† í° ì‹œí€€ìŠ¤ íŒ¨ë”©
        if next_token_seq.shape[1] < max_token_seq:
            next_token_seq = F.pad(
                next_token_seq,
                (0, max_token_seq - next_token_seq.shape[1]),
                "constant",
                value=tokenizer.pad_id,
            )

        # (batch_size, max_token_seq) -> (batch_size, 1, max_token_seq)
        next_token_seq_unsqueeze = next_token_seq.unsqueeze(1)

        # ì…ë ¥ í…ì„œì— ì¶”ê°€
        input_tensor = torch.cat([input_tensor, next_token_seq_unsqueeze], dim=1)

        past_len = cur_len  # ì´ì „ ê¸¸ì´ ì—…ë°ì´íŠ¸ (ì£¼ì˜: ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ì´ë©´ ë‹¤ë¦„)
        cur_len += 1  # ìƒì„±ëœ ì´ë²¤íŠ¸ ìˆ˜ ì¦ê°€
        generated_events_count += 1

        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        progress_percentage = min(
            1.0,
            generated_events_count
            / (total_gen_len - (input_tensor.shape[1] - generated_events_count)),
        )
        if progress_bar:
            progress_bar.progress(progress_percentage)

        # ìƒì„±ëœ í† í° ì‹œí€€ìŠ¤ ë°˜í™˜ (CPUë¡œ ì´ë™)
        yield next_token_seq.cpu().numpy()

        if all(end):  # ëª¨ë“  ë°°ì¹˜ê°€ EOS ìƒì„± ì™„ë£Œ
            st.write("ëª¨ë“  ë°°ì¹˜ì—ì„œ EOS ìƒì„± ì™„ë£Œ.")
            break

    # ìµœì¢… ì§„í–‰ë¥  100%
    if progress_bar:
        progress_bar.progress(1.0)


def synthesis_task(mid_score):
    if synthesizer:
        # MIDI.score2opusê°€ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨
        try:
            opus_data = MIDI.score2opus(mid_score)
            return synthesizer.synthesis(opus_data)
        except Exception as e:
            st.error(f"ì˜¤ë””ì˜¤ í•©ì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    return None


# --- Streamlit UI ---
st.set_page_config(layout="wide")
st.title("ğŸµ MIDI ìƒì„± ëª¨ë¸ (Streamlit ë²„ì „)")

if not _modules_loaded:
    st.stop()

# --- Sidebar ---
with st.sidebar:
    st.header("âš™ï¸ ëª¨ë¸ ì„¤ì •")
    model_paths = get_model_paths()
    selected_model_path = st.selectbox(
        "ëª¨ë¸ íŒŒì¼ ì„ íƒ", model_paths, index=0 if model_paths else -1
    )
    model_configs = ["auto"] + config_name_list
    selected_model_config = st.selectbox("ëª¨ë¸ ì„¤ì • ì„ íƒ", model_configs, index=0)
    lora_paths = get_lora_paths()
    selected_lora_path = st.selectbox("LoRA ê²½ë¡œ ì„ íƒ (ì„ íƒ ì‚¬í•­)", lora_paths, index=0)
    device_options = ["cuda", "cpu"] if torch.cuda.is_available() else ["cpu"]
    selected_device = st.selectbox("ì‹¤í–‰ ì¥ì¹˜", device_options, index=0)

    if st.button("ëª¨ë¸ ë¡œë“œ"):
        with st.spinner("ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            load_msg = load_model(
                selected_model_path,
                selected_model_config,
                selected_lora_path,
                selected_device,
            )
            st.info(load_msg)

    if st.session_state.model_loaded:
        st.success(
            f"ëª¨ë¸ '{Path(selected_model_path).name}' ë¡œë“œë¨ ({selected_device})"
        )
    else:
        st.warning("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”.")

    st.header("ğŸ¹ ì˜¤ë””ì˜¤ í•©ì„±")
    render_audio_checkbox = st.checkbox("ìƒì„± í›„ ì˜¤ë””ì˜¤ ë Œë”ë§", value=True)


# --- Main Area ---
if not st.session_state.model_loaded:
    st.warning("ëª¨ë¸ì„ ë¡œë“œí•œ í›„ ìƒì„± ì˜µì…˜ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

# --- Input Tabs ---
tab1, tab2, tab3 = st.tabs(["Custom Prompt", "MIDI Prompt", "Last Output Prompt"])

with tab1:
    st.subheader("Custom Prompt (ì²˜ìŒë¶€í„° ìƒì„±)")
    input_instruments = st.multiselect(
        "ğŸª— ì•…ê¸° ì„ íƒ (ì—†ìœ¼ë©´ ìë™)",
        options=list(patch2number.keys()),
        max_selections=15,
    )
    input_drum_kit = st.selectbox(
        "ğŸ¥ ë“œëŸ¼ í‚· ì„ íƒ", options=list(drum_kits2number.keys()), index=0
    )  # Default "None"
    input_bpm = st.slider("BPM (0ì´ë©´ ìë™)", 0, 255, 120)
    input_time_sig = st.radio(
        "ë°•ìí‘œ (v2 ëª¨ë¸ìš©)",
        options=[
            "auto",
            "4/4",
            "2/4",
            "3/4",
            "6/4",
            "7/4",
            "2/2",
            "3/2",
            "4/2",
            "3/8",
            "5/8",
            "6/8",
            "7/8",
            "9/8",
            "12/8",
        ],
        index=0,
        horizontal=True,
    )
    input_key_sig = st.radio(
        "ì¡°ì„± (v2 ëª¨ë¸ìš©)", options=["auto"] + key_signatures, index=0, horizontal=True
    )
    selected_tab = 0

with tab2:
    st.subheader("MIDI Prompt (ì…ë ¥ MIDI íŒŒì¼ ê¸°ë°˜)")
    input_midi_file = st.file_uploader(
        "MIDI íŒŒì¼ ì—…ë¡œë“œ (.mid, .midi)", type=["mid", "midi"]
    )
    input_midi_events = st.slider(
        "í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©í•  ì´ˆê¸° MIDI ì´ë²¤íŠ¸ ìˆ˜ (ìµœëŒ€ 4096)", 1, 4097, 128
    )
    # MIDI ì²˜ë¦¬ ì˜µì…˜
    col1, col2 = st.columns(2)
    with col1:
        input_reduce_cc_st = st.checkbox(
            "Control Change/Set Tempo ì´ë²¤íŠ¸ ì¤„ì´ê¸°", value=True
        )
        input_add_default_instr = st.checkbox(
            "ì•…ê¸° ì—†ëŠ” ì±„ë„ì— ê¸°ë³¸ ì•…ê¸° ì¶”ê°€", value=True
        )
    with col2:
        input_remap_track_channel = st.checkbox("íŠ¸ë™/ì±„ë„ ì¬ë§¤í•‘", value=True)
        input_remove_empty_channels = st.checkbox("ë¹ˆ ì±„ë„ ì œê±°", value=False)
    selected_tab = 1


with tab3:
    st.subheader("Last Output Prompt (ì´ì „ ìƒì„± ê²°ê³¼ ì´ì–´í•˜ê¸°)")
    st.write("ë§ˆì§€ë§‰ ìƒì„± ê²°ê³¼ë¥¼ ì´ì–´ì„œ ìƒì„±í•©ë‹ˆë‹¤.")
    # Gradioì˜ Radioì™€ ë‹¬ë¦¬, Streamlitì—ì„œëŠ” ë²„íŠ¼ ë“±ìœ¼ë¡œ íŠ¸ë¦¬ê±° í•„ìš”
    # continuation_options = ["ìƒˆë¡œ ì‹œì‘"] + [f"ê²°ê³¼ {i+1} ì´ì–´í•˜ê¸°" for i in range(DEFAULT_BATCH_SIZE)] # ë°°ì¹˜ ì§€ì› ì‹œ í•„ìš”
    # input_continuation_select = st.radio("ì´ì–´í•  ì¶œë ¥ ì„ íƒ", options=continuation_options, index=0) # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”

    can_undo = len(st.session_state.continuation_state) >= 2
    if st.button("ë§ˆì§€ë§‰ ì´ì–´í•˜ê¸° ì·¨ì†Œ", disabled=not can_undo):
        if can_undo:
            # ìƒíƒœ ë³µì› ë¡œì§
            if isinstance(
                st.session_state.continuation_state[-1], list
            ):  # ì´ì „ ì‹œí€€ìŠ¤ ì €ì¥ë¨
                st.session_state.output_midi_seq = st.session_state.continuation_state[
                    -1
                ]
            else:  # ê¸¸ì´ë§Œ ì €ì¥ë¨
                prev_len = st.session_state.continuation_state[-1]
                if st.session_state.output_midi_seq:
                    # ì£¼ì˜: output_midi_seqê°€ ë°°ì¹˜ í˜•íƒœì¼ ìˆ˜ ìˆìŒ [[seq1], [seq2]]
                    st.session_state.output_midi_seq = [
                        ms[:prev_len] for ms in st.session_state.output_midi_seq
                    ]

            st.session_state.continuation_state = st.session_state.continuation_state[
                :-1
            ]
            st.success("ë§ˆì§€ë§‰ ì´ì–´í•˜ê¸°ë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
            # UI ê°±ì‹ ì„ ìœ„í•´ rerun í•„ìš”
            st.rerun()
        else:
            st.warning("ì·¨ì†Œí•  ì´ì „ ìƒíƒœê°€ ì—†ìŠµë‹ˆë‹¤.")

    selected_tab = 2


# --- Generation Parameters ---
st.divider()
st.subheader("ğŸ² ìƒì„± íŒŒë¼ë¯¸í„°")
col1, col2 = st.columns(2)
with col1:
    input_gen_events = st.slider("ìƒì„±í•  ìµœëŒ€ MIDI ì´ë²¤íŠ¸ ìˆ˜", 1, 4096, 512)
    input_seed = int(
        st.number_input(
            "Seed (ë¬´ì‘ìœ„ëŠ” -1)",
            min_value=-1,
            max_value=MAX_SEED,
            value=st.session_state.last_seed if st.session_state.last_seed != 0 else -1,
        )
    )  # Use -1 for random
    use_random_seed = input_seed == -1
with col2:
    input_temp = st.slider("Temperature", 0.1, 1.2, 1.0, 0.01)
    input_top_p = st.slider("Top-p", 0.1, 1.0, 0.94, 0.01)
    input_top_k = st.slider("Top-k", 1, 128, 20, 1)
    input_allow_cc = st.checkbox("MIDI CC ì´ë²¤íŠ¸ í—ˆìš©", value=True)

# --- Generate Button ---
st.divider()
if st.button(
    "ğŸš€ MIDI ìƒì„± ì‹œì‘!", type="primary", disabled=not st.session_state.model_loaded
):

    model = st.session_state.model
    tokenizer = st.session_state.tokenizer

    if not model or not tokenizer:
        st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        st.stop()

    # --- ì…ë ¥ ì¤€ë¹„ ---
    current_seed = np.random.randint(0, MAX_SEED) if use_random_seed else input_seed
    st.session_state.last_seed = current_seed  # ë‹¤ìŒ ì‹¤í–‰ì„ ìœ„í•´ ì €ì¥
    generator = torch.Generator(next(model.parameters()).device).manual_seed(
        current_seed
    )
    st.write(f"Seed: {current_seed}")

    batch_size = DEFAULT_BATCH_SIZE  # ë°°ì¹˜ í¬ê¸°
    disable_patch_change = False
    disable_channels = None
    prompt_np = None  # ëª¨ë¸ì— ì „ë‹¬ë  ìµœì¢… numpy í”„ë¡¬í”„íŠ¸

    # ì„ íƒëœ íƒ­ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
    if selected_tab == 0:  # Custom Prompt
        st.write("Custom Prompt ì„ íƒë¨")
        prompt_list = [
            [tokenizer.bos_id] + [tokenizer.pad_id] * (tokenizer.max_token_seq - 1)
        ]  # BOS ì´ë²¤íŠ¸
        initial_events_str = ["[BOS]"]

        if tokenizer.version == "v2":
            time_sig = input_time_sig
            if time_sig != "auto":
                time_sig_nn, time_sig_dd = map(int, time_sig.split("/"))
                time_sig_dd_val = {2: 1, 4: 2, 8: 3}.get(
                    time_sig_dd, 2
                )  # ê¸°ë³¸ê°’ 4/4ì˜ dd=2
                event = [
                    "time_signature",
                    0,
                    0,
                    0,
                    time_sig_nn - 1,
                    time_sig_dd_val - 1,
                ]
                prompt_list.append(tokenizer.event2tokens(event))
                initial_events_str.append(f"TimeSig({time_sig})")

            key_sig_name = input_key_sig
            if key_sig_name != "auto":
                key_sig_index = key_sig_map_to_index.get(key_sig_name, 0)
                if key_sig_index != 0:
                    key_sig = key_sig_index - 1
                    key_sig_sf = key_sig // 2 - 7
                    key_sig_mi = key_sig % 2
                    event = ["key_signature", 0, 0, 0, key_sig_sf + 7, key_sig_mi]
                    prompt_list.append(tokenizer.event2tokens(event))
                    initial_events_str.append(f"KeySig({key_sig_name})")

        if input_bpm > 0:
            event = ["set_tempo", 0, 0, 0, input_bpm]
            prompt_list.append(tokenizer.event2tokens(event))
            initial_events_str.append(f"Tempo({input_bpm})")

        patches = {}
        instr_channel_idx = 0
        for instr_name in input_instruments:
            if instr_name in patch2number:
                if instr_channel_idx == 9:
                    instr_channel_idx = 10  # ë“œëŸ¼ ì±„ë„ ê±´ë„ˆë›°ê¸°
                if instr_channel_idx < 16:
                    patches[instr_channel_idx] = patch2number[instr_name]
                    instr_channel_idx += 1
                else:
                    st.warning("ì•…ê¸°ëŠ” ìµœëŒ€ 15ê°œê¹Œì§€ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤ (ë“œëŸ¼ ì œì™¸).")
                    break

        if input_drum_kit != "None":
            if input_drum_kit in drum_kits2number:
                patches[9] = drum_kits2number[input_drum_kit]  # ë“œëŸ¼ì€ ì±„ë„ 9 ê³ ì •

        if patches:
            disable_patch_change = (
                True  # ì‚¬ìš©ìê°€ ì•…ê¸° ì„¤ì • ì‹œ, ì´í›„ ìƒì„±ì—ì„œ patch_change ë§‰ê¸°
            )
            disable_channels = [
                c for c in range(16) if c not in patches
            ]  # ì„¤ì •ë˜ì§€ ì•Šì€ ì±„ë„ ë¹„í™œì„±í™”
            for ch, patch_num in patches.items():
                event = ["patch_change", 0, 0, 0, ch, patch_num]
                prompt_list.append(tokenizer.event2tokens(event))
                instr_name = MIDI.Number2patch.get(patch_num, f"P{patch_num}")
                initial_events_str.append(f"Patch(Ch={ch}, P={instr_name})")

        prompt_np = np.asarray(
            [prompt_list] * batch_size, dtype=np.int64
        )  # (batch, n_events, max_token_seq)
        st.session_state.output_midi_seq = prompt_np.tolist()  # ì´ˆê¸° í”„ë¡¬í”„íŠ¸ë¥¼ ì €ì¥
        st.session_state.continuation_state = [0]  # ìƒíƒœ ì´ˆê¸°í™”
        st.write(f"ì´ˆê¸° í”„ë¡¬í”„íŠ¸ ì´ë²¤íŠ¸: {' '.join(initial_events_str)}")

    elif selected_tab == 1 and input_midi_file is not None:  # MIDI Prompt
        st.write("MIDI Prompt ì„ íƒë¨")
        midi_bytes = input_midi_file.getvalue()
        try:
            # MIDI.midi2score êµ¬í˜„ í•„ìš”
            score = MIDI.midi2score(midi_bytes)
            # í† í¬ë‚˜ì´ì¦ˆ ì˜µì…˜ ì ìš©
            eps = 4 if input_reduce_cc_st else 0
            tokenized_events = tokenizer.tokenize(
                score,
                cc_eps=eps,
                tempo_eps=eps,
                remap_track_channel=input_remap_track_channel,
                add_default_instr=input_add_default_instr,
                remove_empty_channels=input_remove_empty_channels,
            )

            # ì‚¬ìš©í•  ì´ë²¤íŠ¸ ìˆ˜ ì œí•œ
            max_prompt_events = (
                input_midi_events
                if input_midi_events <= 4096
                else len(tokenized_events)
            )
            prompt_events = tokenized_events[:max_prompt_events]

            if not prompt_events:
                st.error("MIDI íŒŒì¼ì—ì„œ ìœ íš¨í•œ ì´ë²¤íŠ¸ë¥¼ í† í°í™”í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                st.stop()

            # BOS ì¶”ê°€ ë° íŒ¨ë”© ì²˜ë¦¬ í•„ìš”? -> í† í¬ë‚˜ì´ì €ê°€ BOS í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
            # Gradio ì½”ë“œëŠ” BOSë¥¼ ì§ì ‘ ì¶”ê°€í•˜ì§€ ì•ŠìŒ. tokenize ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©.
            # ë‹¨, ê° ì´ë²¤íŠ¸ëŠ” max_token_seq ê¸¸ì´ë¡œ ë³€í™˜ë˜ì–´ì•¼ í•¨. tokenize í•¨ìˆ˜ í™•ì¸ í•„ìš”.
            # ë§Œì•½ tokenizeê°€ (n_events, max_token_seq) í˜•íƒœ ë°˜í™˜ ì‹œ:
            prompt_list = prompt_events  # ì´ë¯¸ ì ì ˆí•œ í˜•íƒœë¼ê³  ê°€ì •
            prompt_np = np.asarray([prompt_list] * batch_size, dtype=np.int64)

            # ë§Œì•½ tokenizeê°€ [[tok1, tok2..], [tokA, tokB..]] í˜•íƒœ ë°˜í™˜ ì‹œ íŒ¨ë”© í•„ìš”:
            # padded_prompt_list = []
            # for event_tokens in prompt_events:
            #     padded = event_tokens[:tokenizer.max_token_seq]
            #     if len(padded) < tokenizer.max_token_seq:
            #         padded += [tokenizer.pad_id] * (tokenizer.max_token_seq - len(padded))
            #     padded_prompt_list.append(padded)
            # prompt_np = np.asarray([padded_prompt_list] * batch_size, dtype=np.int64)

            st.session_state.output_midi_seq = prompt_np.tolist()
            st.session_state.continuation_state = [0]  # ìƒíƒœ ì´ˆê¸°í™”
            st.write(
                f"ì…ë ¥ MIDI íŒŒì¼ì—ì„œ {prompt_np.shape[1]}ê°œì˜ ì´ë²¤íŠ¸ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."
            )

        except Exception as e:
            st.error(f"MIDI íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()

    elif selected_tab == 2:  # Last Output Prompt
        st.write("Last Output Prompt ì„ íƒë¨")
        if st.session_state.output_midi_seq:
            # ì´ì „ ê²°ê³¼ ì‚¬ìš©
            prompt_np = np.asarray(st.session_state.output_midi_seq, dtype=np.int64)
            # Gradioì˜ continuation_select ë¡œì§ ë‹¨ìˆœí™”: ë¬´ì¡°ê±´ ë§ˆì§€ë§‰ ê²°ê³¼ ì „ì²´ë¥¼ ì‚¬ìš©
            # ì´ì „ ìƒíƒœ ì €ì¥ (undoìš©)
            if isinstance(
                st.session_state.continuation_state[-1], list
            ):  # ì´ë¯¸ undoí•œ ê²½ìš°
                # ìƒíƒœ ì—…ë°ì´íŠ¸ ì—†ì´ ì§„í–‰
                pass
            else:  # ê¸¸ì´ ì €ì¥
                st.session_state.continuation_state.append(
                    prompt_np.shape[1]
                )  # í˜„ì¬ ê¸¸ì´ë¥¼ ì €ì¥
            st.write(
                f"ì´ì „ ìƒì„± ê²°ê³¼ ({prompt_np.shape[1]} ì´ë²¤íŠ¸)ë¥¼ ì´ì–´ë°›ì•„ ìƒì„±í•©ë‹ˆë‹¤."
            )
        else:
            st.warning("ì´ì–´í•  ì´ì „ ìƒì„± ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. Custom Promptë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            selected_tab = 0  # ê°•ì œë¡œ Custom Promptë¡œ ì „í™˜ (ë˜ëŠ” ì˜¤ë¥˜ ì²˜ë¦¬)
            # Custom Prompt ë¡œì§ ì¬ì‹¤í–‰ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
            prompt_list = [
                [tokenizer.bos_id] + [tokenizer.pad_id] * (tokenizer.max_token_seq - 1)
            ]
            prompt_np = np.asarray([prompt_list] * batch_size, dtype=np.int64)
            st.session_state.output_midi_seq = prompt_np.tolist()
            st.session_state.continuation_state = [0]

    else:  # ì˜ëª»ëœ íƒ­ ì„ íƒ ë˜ëŠ” MIDI íŒŒì¼ ë¯¸ì—…ë¡œë“œ ì‹œ
        st.error("ìœ íš¨í•œ í”„ë¡¬í”„íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()

    # --- ìƒì„± ì‹¤í–‰ ---
    if prompt_np is not None:
        st.write("MIDI ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        progress_bar = st.progress(0.0)
        status_text = st.empty()

        max_len = prompt_np.shape[1] + input_gen_events  # ëª©í‘œ ì´ ì´ë²¤íŠ¸ ìˆ˜

        generated_sequences = [
            list(seq) for seq in prompt_np.tolist()
        ]  # ìƒì„± ê²°ê³¼ ëˆ„ì  (ë°°ì¹˜ ì²˜ë¦¬)

        try:
            midi_generator = generate(
                prompt=prompt_np,
                batch_size=batch_size,
                max_len=max_len,
                temp=input_temp,
                top_p=input_top_p,
                top_k=input_top_k,
                disable_patch_change=disable_patch_change,
                disable_control_change=not input_allow_cc,
                disable_channels=disable_channels,
                generator=generator,
                progress_bar=progress_bar,
            )

            gen_start_time = time.time()
            generated_event_count = 0
            for i, next_token_batch in enumerate(midi_generator):
                # next_token_batch shape: (batch_size, max_token_seq)
                for b in range(batch_size):
                    generated_sequences[b].append(next_token_batch[b].tolist())
                generated_event_count += 1
                status_text.text(
                    f"ì´ë²¤íŠ¸ ìƒì„± ì¤‘... ({generated_event_count}/{input_gen_events})"
                )

            gen_end_time = time.time()
            st.success(
                f"MIDI ìƒì„± ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {gen_end_time - gen_start_time:.2f}ì´ˆ)"
            )
            st.session_state.output_midi_seq = generated_sequences  # ìµœì¢… ê²°ê³¼ ì—…ë°ì´íŠ¸

            # --- ê²°ê³¼ ì²˜ë¦¬ ë° ì¶œë ¥ ---
            st.divider()
            st.subheader("ğŸ¶ ìƒì„± ê²°ê³¼")

            output_dir = "outputs"
            os.makedirs(output_dir, exist_ok=True)
            st.session_state.output_files = []
            st.session_state.output_audio_data = []

            audio_futures = []

            cols = st.columns(batch_size)  # ë°°ì¹˜ ìˆ˜ ë§Œí¼ ì»¬ëŸ¼ ìƒì„±

            for i in range(batch_size):
                with cols[i]:
                    st.markdown(f"**ê²°ê³¼ {i+1}**")
                    final_event_sequence = st.session_state.output_midi_seq[i]

                    # 1. MIDI íŒŒì¼ ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    try:
                        # tokenizer.detokenize êµ¬í˜„ í•„ìš”
                        mid_score = tokenizer.detokenize(final_event_sequence)
                        # MIDI.score2midi êµ¬í˜„ í•„ìš”
                        midi_bytes = MIDI.score2midi(mid_score)

                        output_filename = f"output_{i+1}_{int(time.time())}.mid"
                        output_path = os.path.join(output_dir, output_filename)
                        with open(output_path, "wb") as f:
                            f.write(midi_bytes)
                        st.session_state.output_files.append(output_path)

                        st.download_button(
                            label=f"ê²°ê³¼ {i+1} MIDI ë‹¤ìš´ë¡œë“œ",
                            data=midi_bytes,
                            file_name=output_filename,
                            mime="audio/midi",
                        )

                        # 2. ì˜¤ë””ì˜¤ ë Œë”ë§ (ì„ íƒ ì‚¬í•­)
                        if render_audio_checkbox and synthesizer and thread_pool:
                            future = thread_pool.submit(synthesis_task, mid_score)
                            audio_futures.append(future)
                        else:
                            audio_futures.append(None)  # ì˜¤ë””ì˜¤ ìƒì„± ì•ˆ í•¨

                    except Exception as e:
                        st.error(f"ê²°ê³¼ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                        audio_futures.append(None)

            # 3. ì˜¤ë””ì˜¤ ì¶œë ¥ (ë Œë”ë§ ì™„ë£Œ í›„)
            if render_audio_checkbox:
                with st.spinner("ì˜¤ë””ì˜¤ë¥¼ ë Œë”ë§í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    for i in range(batch_size):
                        with cols[i]:
                            future = audio_futures[i]
                            if future:
                                try:
                                    audio_result = (
                                        future.result()
                                    )  # ìŠ¤ë ˆë“œ ì‘ì—… ì™„ë£Œ ê¸°ë‹¤ë¦¼
                                    if audio_result:
                                        # audio_result í˜•ì‹ í™•ì¸ í•„ìš” (ìƒ˜í”Œë§ ë ˆì´íŠ¸, ë°ì´í„°)
                                        # ì˜ˆ: (44100, opus_bytes) ë˜ëŠ” numpy ë°°ì—´ ë“±
                                        # synthesizer.synthesis ê²°ê³¼ í˜•ì‹ì— ë§ì¶° ì²˜ë¦¬
                                        # ì—¬ê¸°ì„œëŠ” opus_bytesë¥¼ ë°›ì•˜ë‹¤ê³  ê°€ì •í•˜ê³  st.audio ì‚¬ìš©
                                        sampling_rate = 44100  # ê°€ì •
                                        st.audio(
                                            audio_result,
                                            format="audio/opus",
                                            sample_rate=sampling_rate,
                                        )
                                        st.session_state.output_audio_data.append(
                                            audio_result
                                        )
                                    else:
                                        st.warning(f"ê²°ê³¼ {i+1} ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")
                                        st.session_state.output_audio_data.append(None)
                                except Exception as e:
                                    st.error(f"ê²°ê³¼ {i+1} ì˜¤ë””ì˜¤ ë Œë”ë§ ì¤‘ ì˜¤ë¥˜: {e}")
                                    st.session_state.output_audio_data.append(None)
                            else:
                                st.info(f"ê²°ê³¼ {i+1} ì˜¤ë””ì˜¤ ë Œë”ë§ ê±´ë„ˆëœ€")
                                st.session_state.output_audio_data.append(None)

        except Exception as e:
            st.error(f"MIDI ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback

            st.code(traceback.format_exc())  # ë””ë²„ê¹…ì„ ìœ„í•´ ì „ì²´ Traceback ì¶œë ¥

# ì•± ì¢…ë£Œ ì‹œ ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ (ì„ íƒì )
# Streamlitì€ ì¼ë°˜ì ìœ¼ë¡œ ìƒíƒœë¥¼ ìœ ì§€í•˜ë¯€ë¡œ ëª…ì‹œì  ì¢…ë£Œê°€ í•„ìˆ˜ëŠ” ì•„ë‹˜
# def cleanup():
#     if thread_pool:
#         thread_pool.shutdown()
# import atexit
# atexit.register(cleanup)
